{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets and their respective headers\n",
    "data_head_dict = {\n",
    "    'breast-cancer-wisconsin.data' : ['Sample code number', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'class'], \n",
    "    'mushroom.data' : ['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises?', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat'],\n",
    "    'lymphography.data' : ['class', 'lymphatics', 'block of affere', 'bl. of lymph. c', 'bl. of lymph. s', 'by pass', 'extravasates', 'regeneration of', 'early uptake in', 'lym.nodes dimin', 'lym.nodes enlar', 'changes in lym.', 'defect in node', 'changes in node', 'changes in stru', 'special forms', 'dislocation of', 'exclusion of no', 'no. of nodes in'],\n",
    "    'wine.data' : ['class', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline'],\n",
    "    'car.data' : ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class'],\n",
    "    'somerville.data' : ['class', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6'],\n",
    "    'adult.data' : ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'class'],\n",
    "    'bank.data' : ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'class']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for checking data - don't run\n",
    "def count_inst(filestream, class_dict):\n",
    "    n_instances = 0\n",
    "    for line in filestream.readlines()[1:]:\n",
    "        n_instances += 1\n",
    "        class_dict[line.strip().split(\",\")[-1]] += 1\n",
    "    return n_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our total number of instances is: 698\n",
      "For class 2 we have 457 instances.\n",
      "For class 4 we have 241 instances.\n"
     ]
    }
   ],
   "source": [
    "#just for checking data - don't run\n",
    "class_dict = defaultdict(int)\n",
    "f=open(\"wine.data\", 'r')\n",
    "print('Our total number of instances is:',count_inst(f,class_dict))\n",
    "for lbl in class_dict.keys():\n",
    "    print('For class', lbl, 'we have', class_dict[lbl], 'instances.')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for checking data - don't run\n",
    "def check_data(filestream,n_fields):\n",
    "    ret_val = True\n",
    "    for line in filestream:\n",
    "        if (len(line.strip().split(\",\"))!=n_fields): ret_val = False\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header:  ['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises?', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat']\n",
      "CSV passes?  True\n"
     ]
    }
   ],
   "source": [
    "#just for checking data - don't run\n",
    "f = open(\"mushroom.data\",'r')\n",
    "\n",
    "header = data_head_dict[\"mushroom.data\"]\n",
    "print(\"Header: \",header)\n",
    "n_fields = len(header)\n",
    "\n",
    "print(\"CSV passes? \",check_data(f,n_fields))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should prepare the data by reading it from a file and converting it into a useful format for training and testing\n",
    "def preprocess_rest(filename):\n",
    "    df = pd.read_csv(filename, names=data_head_dict[filename])\n",
    "    names=data_head_dict[filename]\n",
    "    if filename == \"wine.data\" or filename == \"somerville.data\":\n",
    "        for header in names:\n",
    "            #removing rows with '?'\n",
    "            df.drop(df.loc[df[header]=='?'].index, inplace=True)\n",
    "    return df\n",
    "\n",
    "#This is for discretising the datasets\n",
    "def preprocess_wine(filename):\n",
    "        \n",
    "    # read data and add column headers\n",
    "    df = pd.read_csv(filename, names=data_head_dict[filename])\n",
    "    names=data_head_dict[filename]\n",
    "    #discretising and splitting continuous data into 3 bins\n",
    "    for header in names:\n",
    "        if header != 'class':\n",
    "            minimum = df[header].min()\n",
    "            maximum = df[header].max()\n",
    "            step = (maximum-minimum)/3\n",
    "            df[header]=pd.cut(x = df[header], \n",
    "                              bins = [minimum,minimum+step,maximum-step, \n",
    "                                      maximum], labels = [0, 1, 2])\n",
    "    return df\n",
    "\n",
    "def preprocess_adult(filename):\n",
    "        \n",
    "    # read data and add column headers\n",
    "    df = pd.read_csv(filename, names=data_head_dict[filename])\n",
    "    continuous = [\"age\", \"fnlwgt\", \"education-num\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]\n",
    "    for header in continuous:\n",
    "        minimum = df[header].min()\n",
    "        maximum = df[header].max()\n",
    "        step = (maximum-minimum)/3\n",
    "        df[header]=pd.cut(x = df[header], bins = [minimum,minimum+step,maximum-step, maximum], labels = [0, 1, 2])\n",
    "    #removing rows with '?'\n",
    "    for header in data_head_dict[filename]:\n",
    "        df.drop(df.loc[df[header]=='?'].index, inplace=True)\n",
    "    return df\n",
    "\n",
    "def preprocess_bank(filename):\n",
    "        \n",
    "    # read data and add column headers\n",
    "    df = pd.read_csv(filename, names=data_head_dict[filename])\n",
    "    continuous = [\"age\", \"balance\", \"day\", \"duration\", \"campaign\"]\n",
    "    for header in continuous:\n",
    "            minimum = df[header].min()\n",
    "            maximum = df[header].max()\n",
    "            step = (maximum-minimum)/3\n",
    "            df[header]=pd.cut(x = df[header], \n",
    "                              bins = [minimum,minimum+step,maximum-step, \n",
    "                                      maximum], labels = [0, 1, 2])\n",
    "            \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should calculate prior probabilities and likelihoods from the training data and using\n",
    "# them to build a naive Bayes model\n",
    "\n",
    "def train(training_set, filename):\n",
    "    prior = {}\n",
    "    distinct_class = []\n",
    "    length_training_set = len(training_set)\n",
    "    class_column = training_set['class']\n",
    "    for class_header in class_column:\n",
    "        if class_header not in distinct_class:\n",
    "            distinct_class.append(class_header)\n",
    "    total = training_set['class'].value_counts().to_dict()\n",
    "    for header in distinct_class:\n",
    "        #storing prior probability of each class\n",
    "        prior[header] = total[header]/length_training_set\n",
    "\n",
    "    if filename == \"wine.data\" or filename == \"somerville.data\":\n",
    "        #continuous data\n",
    "        #calculating variance and mean dataset\n",
    "        data_variance=training_set.groupby('class', as_index=False).var()\n",
    "        data_variance\n",
    "\n",
    "        data_mean=training_set.groupby('class', as_index=False).mean()\n",
    "        data_mean\n",
    "\n",
    "        #calculate mean of each attribute per class\n",
    "        d_means = {}\n",
    "        headers = training_set.columns\n",
    "        for class_header in distinct_class:\n",
    "            temp = data_mean.loc[data_mean['class'] == class_header].to_numpy()\n",
    "            d_means[class_header] = temp[0][1:]\n",
    "\n",
    "        #calculate variance of each attribute per class\n",
    "        d_variances = {}\n",
    "        for class_header in distinct_class:\n",
    "            temp = data_variance.loc[data_variance['class'] == class_header].to_numpy()\n",
    "            d_variances[class_header] = temp[0][1:]\n",
    "        return d_means, d_variances, prior   \n",
    "    #else:\n",
    "        #categorical data\n",
    "        #did'nt have time to do this part :(\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from math import pi\n",
    "from math import exp\n",
    "#calculates p(x|y), the probability density of one term of the likelihood\n",
    "def calculate_probability(x, mean, var):\n",
    "    exponent = exp(-((x-mean)**2 / (2 * var )))\n",
    "    return (1 / (sqrt(2 * pi) * sqrt(var))) * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicts classes of instances from the testing_set\n",
    "def predict(testing_set, d_means, d_variances, prior):\n",
    "    class_headers = testing_set['class']\n",
    "    testing_set = testing_set.drop('class', 1)\n",
    "    predictions = {}\n",
    "    predicted_class = {}\n",
    "    total_probability = 1\n",
    "    count = 0\n",
    "    for i in range(len(class_headers)): \n",
    "        feature = testing_set.iloc[i]\n",
    "        for class_header in prior.keys(): \n",
    "            for attribute in testing_set.columns:\n",
    "                total_probability*=calculate_probability(feature[attribute], d_means[class_header][count], d_variances[class_header][count])\n",
    "                count+=1\n",
    "            #calculating numerator of posterior for each class\n",
    "            total_probability*=prior[class_header]\n",
    "            predictions[class_header] = total_probability\n",
    "            total_probability = 1\n",
    "            count = 0\n",
    "            total_probability\n",
    "        #storing the class with the highest probability since that is the prediction\n",
    "        predicted_class[i] = max(predictions, key=predictions.get)\n",
    "\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks if predicted_class is the same as class_headers and returns accuracy\n",
    "def evaluate(predicted_class, testing_set):\n",
    "    class_headers = testing_set['class']\n",
    "    count=0\n",
    "    for i in range(len(class_headers)):\n",
    "        if class_headers.iloc[i] == predicted_class[i]:\n",
    "            count+=1\n",
    "    accuracy = count/len(class_headers)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For wine.data we have:\n",
      "Number of features (columns): 14\n",
      "Number of instances (rows): 178\n",
      "Accuracy: 0.988764\n",
      "For somerville.data we have:\n",
      "Number of features (columns): 7\n",
      "Number of instances (rows): 143\n",
      "Accuracy: 0.608392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "#running and printing relvant info on datasets\n",
    "wine = preprocess_rest(\"wine.data\")\n",
    "mean,var,prior = train(wine, \"wine.data\")\n",
    "pred = predict(wine, mean, var, prior)\n",
    "acc_wine = evaluate(pred, wine)\n",
    "\n",
    "somerville = preprocess_rest(\"somerville.data\")\n",
    "mean,var,prior = train(somerville, \"somerville.data\")\n",
    "pred = predict(somerville, mean, var, prior)\n",
    "acc_somerville = evaluate(pred, somerville)\n",
    "\n",
    "print(\"For wine.data we have:\")\n",
    "print(\"Number of features (columns): %d\" % len(wine.columns))\n",
    "print(\"Number of instances (rows): %d\" % len(wine))\n",
    "print(\"Accuracy: %f\" % acc_wine)\n",
    "\n",
    "print(\"For somerville.data we have:\")\n",
    "print(\"Number of features (columns): %d\" % len(somerville.columns))\n",
    "print(\"Number of instances (rows): %d\" % len(somerville))\n",
    "print(\"Accuracy: %f\" % acc_somerville)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretising continuous variables, then passing it through the classifier on average yielded the same performance. The wine dataset yielded a 98.89% without discretising and 100% when discretising in the preprocess stage. However, this is pretty trivial as both the continuous data and discrete data produced very high results. On the other hand the adult and bank datasets yielded around 25% originally and 27% when the continuous variables were discretised. All three datasets were discretised into 3 equal width bins. Using more bins yielded very similar results. We can see that discretising continuous variables yields a very small but greater accuracy. This means that discretisation preserves the conditional probability of each class for each instance. While we do see a small increase in accuracy, we can conclude that discretisation has little to no effect on the datasets and yields similar performance to continuous data in the naive bayes classifier.\n",
    "\n",
    "\n",
    "The ordinal dataset “somerville.data” was treated as a numeric variable. Simply by comparing accuracies between “somerville.data” and “wine.data” which is originally a numeric dataset, we can see that the ordinal data has an accuracy of 60.84% where the numeric data has an accuracy of 98.89%. If we look at the number of features and instances of these datasets, the wine dataset has more features and instances with 178 instances and 14 features whereas the somerville dataset has 143 instances and 7 features. Despite having more features and instances the wine dataset outperformed the somerville dataset by nearly 40%. This implies that the classification prefers numeric data and finds it difficult to predict ordinal data that are treated as numeric, especially since the wine dataset yielded nearly a 100% accuracy. However, testing was done on the same data as the training, so results would naturally be higher than if we tested the data on unknown instances.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
